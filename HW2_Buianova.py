'''
Домашнее задание:
Взять набор данных – выборку из корпуса про судебные разбирательства. На основании этих данных выделить наиболее
типичные для суда действия (словосочетания типа принять решение), применив два различных метода.
Методы могут различаться:
выбором двух разных метрик;
выбором разных ограничений на части речи и ширину окна (сравнить один и тот же метод при разных ограничениях);
... либо вы выбираете метод и ограничения, смотрите на результат и предлагаете какие-то эвристики, которые позволяют
улучшить результат.

Для оценки результата:
Пользуясь словарями, интуицией и т.п. составляете золотой стандарт – ранжированный топ 10 коллокаций.
Смотрите, какую позицию занимают коллокации из золотого стандарта среди списка, отранжированного по мере коллокационной
связи.
Считаете меру качества – ранговый коэффициент корреляции Спирмена между двумя списками.

Итогом работы является скрипт на питоне, который либо использует nltk, либо вами вручную написанную функцию для подсчета
коллокационной метрики. В конце скрипта нужно приписать вывод, в котором вы пишете, что вы сделали: какие методы
использовали, какой результат получили и что вы об этом думаете.
'''
import nltk
from nltk.collocations import *
from nltk.metrics.spearman import *
bigram_measures = nltk.collocations.BigramAssocMeasures()
trigram_measures = nltk.collocations.TrigramAssocMeasures()

# массив - золотой стандарт, 2-граммы отобраны интуитивно
gold_standart = [('ВЫНЕСТИ', 'ПРИГОВОР'),
                 ('ОТКЛОНИТЬ','ИСК'),
                 ('УДОВЛЕТВОРИТЬ', 'ИСК'),
                 ('ПРИНЯТЬ', 'РЕШЕНИЕ'),
                 ('СУД', 'УДОВЛЕТВОРИТЬ'),
                 ('ВЕСТИ', 'ПРОЦЕСС'),
                 ('ОРДЕР', 'АРЕСТ'),
                 ('ДОВОД', 'ПРОКУРОР'),
                 ('ВЫЗВАТЬ', 'СВИДЕТЕЛЬ'),
                 ('ВЫСЛУШАТЬ', 'ЗАЩИТА')]

#открываем файл и записываем в массив все отдельные слова из файла без знаков препинания и пробелов

file = open('court-V-N.csv', 'r', encoding='utf-8')
words = []
for word in file:
    word = word.strip().split(',')
    for w in word:
        w = w.replace(' ', '').replace('    ', '').replace('  ', '').replace('\n', '')
        words.append(w)
file.close()

# составляем список 2-грамм
bigram_measures = nltk.collocations.BigramAssocMeasures()
finder = BigramCollocationFinder.from_words(words)

# топ-10 по Стьюденту
student = finder.nbest(bigram_measures.student_t, 10)
print('Топ-10 Стьюдент:', (student))

# смотрим топ-10 по LogLikelihood
log_likelihood = finder.nbest(bigram_measures.likelihood_ratio, 10)
print('\n', 'Топ-10 LogLiklihood:', (log_likelihood))

'''
# ещё как вариант, топ-10 по Chi-square
chi_square = finder.nbest(bigram_measures.chi_sq, 10)
print(chi_square)'''

print('\n', 'Мой золотой стандарт', (gold_standart))

#ранговый коэффициент корреляции Спирмена между двумя списками
# 1. золотой стандарт - Стьюдент
print('\n', 'Золотой стандарт - Стьюдент:', (spearman_correlation(ranks_from_sequence(gold_standart),
                                                           ranks_from_sequence(student))))

# 2. золотой стандарт - LogLiklihood
print('Золотой стандарт - LogLiklihood:', (spearman_correlation(ranks_from_sequence(gold_standart),
                                                                ranks_from_sequence(log_likelihood))))

# Вывод
print('Вывод: наверное, я что-то сделала не так, но обе корелляции Спирмена (по Стьюденту и логу)показывают результат больше 1. Но если смотреть вручную, то 2 биграммы совпадают с золотым стандартом в обоих слуучаях: принять решение, суд удовлетворить.')

'''
Вывод: наверное, я что-то сделала не так, но обе корелляции Спирмена (по Стьюденту и логу)
показывают результат больше 1. Но если смотреть вручную, то 2 биграммы совпадают с золотым
стандартом в обоих слуучаях: принять решение, суд удовлетворить.
'''
